{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indel candidacy is determined by observing sufficient counts of reads supporting the indel vs. all reads supporting the indel or an alternate allele at that locus. Sufficient counts in this case is determined by rejecting a null hypothesis of a per read indel error process occuring at the indel error rate (p) for a given alpha, as originally setup by Mitch Bekritsky:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GetCountsToRejectNull <- function(alpha, n_trials, p) {\n",
    "  counts <- 1 + qbinom(alpha, n_trials, p, lower.tail = FALSE)\n",
    "  return (counts)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare models we setup some counts table printing boilerplate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coverageLevels <- 1:10*10\n",
    "DumpCov <- function() {\n",
    "  cat(\"coverage\")\n",
    "  for (cov in coverageLevels){\n",
    "    cat(paste(\"\\t\",cov))\n",
    "  }\n",
    "  cat(\"\\n\")\n",
    "}\n",
    "\n",
    "PrintCountsToReject <- function(alpha, errorRate, label) {\n",
    "  cat(label)\n",
    "  for (cov in coverageLevels){\n",
    "    cat(paste(\"\\t\",GetCountsToRejectNull(alpha, cov, errorRate)))\n",
    "  }\n",
    "  cat(\"\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The v2.7.x candidacy model is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coverage\t 10\t 20\t 30\t 40\t 50\t 60\t 70\t 80\t 90\t 100\n",
      "nonSTRIndel\t 3\t 3\t 3\t 4\t 4\t 4\t 4\t 4\t 4\t 4\n",
      "hpol16+Indel\t 4\t 4\t 4\t 4\t 5\t 5\t 5\t 5\t 5\t 5\n"
     ]
    }
   ],
   "source": [
    "alpha <- 1e-9\n",
    "DumpCov()\n",
    "PrintCountsToReject(alpha, 5e-5, \"nonSTRIndel\")\n",
    "PrintCountsToReject(alpha, 3e-4, \"hpol16+Indel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how this model merges together the previous 10% cutoff behavior chosen for old versions of the germline model, with a plateauing evidence requirement at high coverage, as we would like for somatic models.\n",
    "\n",
    "Attempting to make the candidate model more \"consistent\" by using the same indel error rates we use for the germline indel likelihood generation tends to reduce F-scores compared to using the old candidacy model. Looking at the tables suggests why.\n",
    "\n",
    "Here is the first attemp to just use the indel error rates from v2.7.x (so the same rates as shown above, times 100). Alpha has been scaled to produce a similar number of candidates on a ~35x example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coverage\t 10\t 20\t 30\t 40\t 50\t 60\t 70\t 80\t 90\t 100\n",
      "nonSTRIndel\t 2\t 2\t 2\t 3\t 3\t 3\t 3\t 3\t 4\t 4\n",
      "hpol16+Indel\t 3\t 4\t 5\t 5\t 6\t 6\t 7\t 8\t 8\t 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alpha <- 1e-2\n",
    "DumpCov()\n",
    "PrintCountsToReject(alpha, 5e-3, \"nonSTRIndel\")\n",
    "PrintCountsToReject(alpha, 3e-2, \"hpol16+Indel\")\n",
    "cat(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very different response as a function of depth, as expected. This doesn't suggest to me that our indel error rates are wrong, so much as the null rejection test isn't what we really want. In v2.7.x the combination of the \"not-quite-right\" rates and the \"not-quite-right\" test happens to have all the properties we're looking for.\n",
    "\n",
    "UPdating indel error rates to the ones we actually estimate from data (shown here is the geometric avg of Nano and PCR-free), doesn't really change the problems with this approach, as is also observed in similar F-score drops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coverage\t 10\t 20\t 30\t 40\t 50\t 60\t 70\t 80\t 90\t 100\n",
      "nonSTRIndel\t 2\t 3\t 3\t 4\t 4\t 4\t 5\t 5\t 5\t 5\n",
      "hpol16+Indel\t 4\t 5\t 6\t 7\t 8\t 8\t 9\t 10\t 11\t 11\n"
     ]
    }
   ],
   "source": [
    "alpha <- 1e-2\n",
    "DumpCov()\n",
    "PrintCountsToReject(alpha, 1.2e-2, \"nonSTRIndel\")\n",
    "PrintCountsToReject(alpha, 4.9e-2, \"hpol16+Indel\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
